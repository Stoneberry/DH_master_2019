{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation, digits\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "punct = punctuation+'«»—…“”*№–'+digits\n",
    "stops = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1. \n",
    "Напишите сами любой алгоритм извлечения ключевых слов. Какой угодно, пусть даже интуитивно он будет нелепый, неважно. Конечно, будет интересно придумать что-то хитрое, с опорой на лингвистику (пока ее тут почти что не было). Или свой графовый алгоритм -- можно с networkx, а не на матрицах:) Еще круче, если вы сделаете не только слова, но и фразы (чтобы был шанс выловить \"образовательные стандарты\" или \"леонида юзефовича\" целиком). Но можно и воспроизвести что-то из того, что есть выше. Но только не копируйте код, а пишите сами, воспроизводя логику."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/book_dh/1925_Bulgakov_Sobache serdce.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stop_words.txt', 'r', encoding='utf-8') as f:\n",
    "    stops = f.read()\n",
    "    stops.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    words = []\n",
    "    for word in word_tokenize(text.lower()):\n",
    "        word = word.strip(punct)\n",
    "        word = morph.parse(word)[0].normal_form\n",
    "        if word and word not in stops: \n",
    "            words.append(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "За последние сутки в Бельгии от коронавируса скончались 313 человек, общее число умерших с начала распространения вируса составило 5136, говорится в сообщении кризисного центра министерства здравоохранения королевства.\n",
    "Также за минувшие сутки было диагностировано 1329 новых случаев заражения коронавирусом, общее число заболевших составляет 36138 человек.\n",
    "При этом, бельгийские власти констатируют снижение числа госпитализированных с коронавирусом, а также пациентов, находящихся в интенсивной терапии.\n",
    "Всего с начала распространения вируса из больниц был выписан 7961 инфицированный COVID-19.\n",
    "В минувшую среду власти Бельгии продлили меры социальной изоляции до 3 мая. В начале мая, как ожидается, страна начнет постепенно выходить из \"карантина\".\n",
    "Врачи предупреждают, что в ближайшие дни цифры по зараженным, возможно, увеличатся, поскольку несколько дней назад власти организовали проведение тестов на коронавирус в домах престарелых, где их раньше не проводили...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rapid Automatic Keyword Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я решила опробовать алгоритм RAKE на материале русского языка. Алгоритм заключается в том, что текст делится на по стоп словам на последовательности слов. Далее каждой из этих последоватлеьностей присваивается скор, которые равен делению степени встречаемости слов с другими словами на частотность слов. Алгоритм неплохо работает на материале английского языка. Скорее всего на материале русского языка алготим вменяемых результатов показывать не будет, так как в русском языке стоп слова в тексте встрчаются намного реже. Например, в русском языке нет артиклей. Проверим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import string\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = '[?.,!@#$%^&*()_+=-{}/\\|\":;><\"\\n]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = defaultdict(int)\n",
    "phrases = []\n",
    "\n",
    "for sent in re.split(punc, text):\n",
    "    line = []\n",
    "    if sent != '':\n",
    "        for word in word_tokenize(sent.lower()):\n",
    "            word = word.strip(punct)\n",
    "            word = morph.parse(word)[0].normal_form\n",
    "            if word in stops or word.isdigit():\n",
    "                if line != []:\n",
    "                    phrases.append(line)\n",
    "                    line = []\n",
    "            elif word != '': \n",
    "                line.append(word)\n",
    "                word_freq[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(word_freq.keys())\n",
    "n_col = len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Матрица встречаемости слов\n",
    "* Степени слов\n",
    "* Скор каждого слова\n",
    "* Скор последовательностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_matrix = np.zeros((n_col, n_col), dtype=float, order='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in phrases:\n",
    "    for w in itertools.permutations(line, 2):\n",
    "        ind_a, ind_b = words.index(w[0]), words.index(w[1])\n",
    "        freq_matrix[ind_a][ind_b] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Степени слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_degree = np.sum(freq_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скор каждого слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_score = {word: word_degree[words.index(word)]/word_freq[word] for word in word_freq}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скор последовательностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rake_score(phrases, word_score, top=4):\n",
    "\n",
    "    phr_score = {}\n",
    "\n",
    "    for line in phrases: \n",
    "        s = [word_score[word] for word in line]\n",
    "        phr_score[' '.join(line)] = sum(s)\n",
    "    \n",
    "    phr_score = sorted(phr_score.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    #return phr_score[:top]\n",
    "    return [i[0] for i in phr_score[:top]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('поскольку несколько день назад власть организовать проведение тест',\n",
       "  52.83333333333333),\n",
       " ('минувший среда власть бельгия продлить мера социальный изоляция',\n",
       "  48.83333333333333),\n",
       " ('бельгийский власть констатировать снижение число госпитализировать',\n",
       "  28.666666666666664),\n",
       " ('страна начать постепенно выходить', 12.0)]"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rake_score(phrases, word_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что алгоритм показывает себя очень плохо для задачи выявления ключевых слов на русском языке. Последовательности слишком длинные, так как не содержат стоп слов. Попробуем добавить в список фраз отдельные слова. Однако неплохо выявляет ключевые мысли."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_w = []\n",
    "\n",
    "for word in word_freq:\n",
    "    ind, freq = words.index(word), word_freq[word]\n",
    "    freq_matrix[ind_a][ind_b] += ind * freq\n",
    "    new_w.append([word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('поскольку несколько день назад власть организовать проведение тест',\n",
       "  8344.833333333334),\n",
       " ('тест', 8299.0),\n",
       " ('минувший среда власть бельгия продлить мера социальный изоляция',\n",
       "  48.83333333333333),\n",
       " ('бельгийский власть констатировать снижение число госпитализировать',\n",
       "  28.666666666666664)]"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_degree = np.sum(freq_matrix, axis=1)\n",
    "word_score = {word: word_degree[words.index(word)]/word_freq[word] for word in word_freq}\n",
    "rake_score(phrases + new_w, word_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалось вывести в топ слово \"тест\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем делить на кол-во слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rake_score2(phrases, word_score, top=4):\n",
    "\n",
    "    phr_score = {}\n",
    "\n",
    "    for line in phrases: \n",
    "        s = [word_score[word] for word in line]\n",
    "        phr_score[' '.join(line)] = sum(s)/len(line)\n",
    "    \n",
    "    phr_score = sorted(phr_score.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    #return phr_score[:top]\n",
    "    return [i[0] for i in phr_score[:top]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('тест', 8299.0),\n",
       " ('поскольку несколько день назад власть организовать проведение тест',\n",
       "  1043.1041666666667),\n",
       " ('среда', 7.0),\n",
       " ('продлить', 7.0),\n",
       " ('мера', 7.0),\n",
       " ('социальный', 7.0)]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_degree = np.sum(freq_matrix, axis=1)\n",
    "word_score = {word: word_degree[words.index(word)]/word_freq[word] for word in word_freq}\n",
    "rake_score2(phrases + new_w, word_score, top=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А что если искуственно делить получившиеся последовательности на несколько меньших?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_phrases = []\n",
    "\n",
    "for line in phrases: \n",
    "    if len(line) > 3:\n",
    "        for i in range(2, 4):\n",
    "            for ng in ngrams(line, i):\n",
    "                new_phrases.append(ng)\n",
    "    else: new_phrases.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_matrix = np.zeros((n_col, n_col), dtype=float, order='C')\n",
    "\n",
    "for line in phrases:\n",
    "    for w in itertools.permutations(line, 2):\n",
    "        ind_a, ind_b = words.index(w[0]), words.index(w[1])\n",
    "        freq_matrix[ind_a][ind_b] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('продлить мера', 7.0),\n",
       " ('мера социальный', 7.0),\n",
       " ('социальный изоляция', 7.0),\n",
       " ('продлить мера социальный', 7.0),\n",
       " ('мера социальный изоляция', 7.0),\n",
       " ('поскольку несколько', 7.0)]"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_degree = np.sum(freq_matrix, axis=1)\n",
    "word_score = {word: word_degree[words.index(word)]/word_freq[word] for word in word_freq}\n",
    "rake_score2(new_phrases, word_score, top=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С добавлением отдельных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('организовать проведение тест', 2785.0),\n",
       " ('проведение тест', 2778.0),\n",
       " ('тест', 2771.0),\n",
       " ('продлить мера социальный', 21.0),\n",
       " ('мера социальный изоляция', 21.0),\n",
       " ('назад власть организовать', 20.333333333333332)]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in word_freq:\n",
    "    ind, freq = words.index(word), word_freq[word]\n",
    "    freq_matrix[ind_a][ind_b] += ind * freq\n",
    "\n",
    "word_degree = np.sum(freq_matrix, axis=1)\n",
    "word_score = {word: word_degree[words.index(word)]/word_freq[word] for word in word_freq}\n",
    "rake_score(new_phrases + new_w, word_score, top=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('тест', 2771.0),\n",
       " ('проведение тест', 1389.0),\n",
       " ('организовать проведение тест', 928.3333333333334),\n",
       " ('продлить мера', 7.0),\n",
       " ('мера социальный', 7.0),\n",
       " ('социальный изоляция', 7.0)]"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rake_score2(new_phrases + new_w, word_score, top=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, результаты стали намного лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2\n",
    "Возьмите любой собственный набор текстов. Примените алгоритм к текстам, выведите результаты на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ng_maker(line):\n",
    "    new_phrases = [ng for i in range(2, 4) for ng in ngrams(line, i)]\n",
    "    return new_phrases\n",
    "    \n",
    "def phrases_maker(text):\n",
    "\n",
    "    word_freq = defaultdict(int)\n",
    "    phrases = []\n",
    "\n",
    "    for sent in re.split(punc, text):\n",
    "       \n",
    "        if sent != '':\n",
    "            pos, line = [], []\n",
    "            for word in word_tokenize(sent.lower()):\n",
    "                word = word.strip(punct)\n",
    "                mrph = morph.parse(word)[0]#.normal_form\n",
    "                #word = mrph.normal_form\n",
    "       \n",
    "                if mrph.tag.POS in ('ADJF', 'NOUN', 'PRTF'):\n",
    "                    if mrph.tag.POS == 'NOUN': \n",
    "                        phrases.append([mrph.normal_form])\n",
    "                        word_freq[mrph.normal_form] += 1\n",
    "                    line.append(word)\n",
    "                    word_freq[word] += 1\n",
    "                    pos.append(mrph.tag.POS)\n",
    "                    \n",
    "                elif len(pos) > 1 and 'NOUN' in set(pos):\n",
    "            \n",
    "                    if len(line) > 3:\n",
    "                        lines = ng_maker(line)\n",
    "                        phrases += lines\n",
    "                        line, pos = [], []\n",
    "                    elif line != []:\n",
    "                        phrases.append(line)\n",
    "                        line, pos = [], []\n",
    "         \n",
    "    return word_freq, phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_martix(phrases, words, word_freq, n_col):\n",
    "    \n",
    "    freqm = np.zeros((n_col, n_col), dtype=float, order='C')\n",
    "    \n",
    "    for line in phrases:\n",
    "        if len(line) == 1:\n",
    "            ind, freq = words.index(line[0]), word_freq[line[0]]\n",
    "            freqm[ind][ind] += ind * freq\n",
    "        else:\n",
    "            for w in itertools.permutations(line, 2):\n",
    "                ind_a, ind_b = words.index(w[0]), words.index(w[1])\n",
    "                freqm[ind_a][ind_b] += 1\n",
    "    return freqm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rake_keywords(text, top=6):\n",
    "    word_freq, phrases = phrases_maker(text)\n",
    "    words = list(word_freq.keys())\n",
    "    n_col = len(words)\n",
    "    freq_matrix = freq_martix(phrases, words, word_freq, n_col)   \n",
    "    word_degree = np.sum(freq_matrix, axis=1)\n",
    "    word_score = {word: word_degree[words.index(word)]/word_freq[word] for word in word_freq}\n",
    "    res = rake_score(phrases, word_score, top=top)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['день',\n",
       " 'май',\n",
       " 'власть',\n",
       " 'дом',\n",
       " 'проведение тестов',\n",
       " 'тест',\n",
       " 'проведение',\n",
       " 'цифра',\n",
       " 'врач',\n",
       " 'карантин',\n",
       " 'страна',\n",
       " 'изоляция',\n",
       " 'мера',\n",
       " 'среда',\n",
       " 'больница',\n",
       " 'терапия']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rake_keywords(text, top=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1824_Bulgarin_Pravdopodobnye nebylicy, ili Stranstvovaniya po svetu v dvadcat' devyatom veke.txt\n",
      "['суда проводник мой', 'мой проводник', 'проводник мой', 'проводник', 'принц телескоп']\n",
      "\n",
      "1899_Bryusov_Gora Zvezdy.txt\n",
      "['царевна сеата', 'царица сеата', 'все время царевна', 'царевна знаком надсмотрщика', 'царевна розовые']\n",
      "\n",
      "1903_Bryusov_Respublika Yuzhnogo Kresta.txt\n",
      "['дивиль сношение', 'трагедии орас дивиль', 'события орас дивиль', 'дивиль городские хлебопекарни', 'орас дивиль']\n",
      "\n",
      "1925_Belyaev_Golova professora Douelya.txt\n",
      "['шауб жертву равино', 'ларь', 'брик', 'дверей доктор равино', 'доктор равино']\n",
      "\n",
      "1925_Belyaev_Poslednij chelovek iz Atlantidy.txt\n",
      "['акса-гуам камень', 'время акса-гуам', 'акса-гуам последнего отплывавшего', 'акса-гуам последнего', 'акса-гуам им ту']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'Мага/book_dh'\n",
    "count = 6\n",
    "\n",
    "for file_name in os.listdir(path):\n",
    "    if file_name != '.DS_Store':\n",
    "        with open(path + '/' + file_name, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            keys = rake_keywords(text, top=5)\n",
    "            count -= 1\n",
    "            if count == 0: break\n",
    "            print(file_name)\n",
    "            print(keys)\n",
    "            print()\n",
    "            #print('{}: {}'.format(file_name, ' '.join(keys)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 3\n",
    "Протестируйте алгоритм на любом документе (документах) из датасета https://github.com/mannefedov/ru_kw_eval_datasets Будет хорошо, если вы напишете свою функцию измерения точности, полноты и F-меры. Желающие могут добавить туде еще расчет кэффициента близости Жаккара."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'ng_1.jsonlines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_1_data = []\n",
    "with open(path, \"r\") as read_file:\n",
    "    for line in read_file:\n",
    "        ng_1_data.append(json.loads(line)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['keywords', 'title', 'url', 'content', 'summary'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng_1_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_pos_distance(a, b):\n",
    "    return 1.0 * len(a&b)/len(a|b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions_freq, recalls_freq, jac_freq = [], [], []\n",
    "precisions_rake, recalls_rake, jac_rake = [], [], []\n",
    " \n",
    "for text in ng_1_data:\n",
    "    freq = Counter(normalize(text['content'])).most_common(6)\n",
    "    freq = set([i[0] for i in freq])\n",
    "    \n",
    "    rake = set(rake_keywords(text['content'], top=6))\n",
    "    real = set(text['keywords'])\n",
    "    common = len(rake & real)\n",
    "    \n",
    "    jac_freq.append(jaccard_pos_distance(rake, real))\n",
    "    recalls_freq.append(common/len(real)) \n",
    "    precisions_freq.append(common/len(rake))\n",
    "    \n",
    "    jac_rake.append(jaccard_pos_distance(freq, real))\n",
    "    recalls_rake.append(common/len(real)) \n",
    "    precisions_rake.append(common/len(freq))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(precisions, recalls, jac):\n",
    "    precision = np.mean(precisions)\n",
    "    recall = np.mean(recalls)\n",
    "    jac = np.mean(jac)\n",
    "    fscore = 2 * ((precision * recall) / (precision + recall))\n",
    "    return precision, recall, fscore, jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0298582995951417,\n",
       " 0.02879244715024067,\n",
       " 0.029315688573286727,\n",
       " 0.015498502077112584)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(precisions_freq, recalls_freq, jac_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FREQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0298582995951417,\n",
       " 0.02879244715024067,\n",
       " 0.029315688573286727,\n",
       " 0.08516762493792143)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(precisions_rake, recalls_rake, jac_rake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень все плохо, но на тестовой новосте нормально."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
